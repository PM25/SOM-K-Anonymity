{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "from minisom import MiniSom\n",
    "\n",
    "import time\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    # Load Adult dataset and seperate to features(X) and target(y)\n",
    "    def __init__(self, path='data/adult.csv'):\n",
    "        df = shuffle(pd.read_csv(path))\n",
    "        df = self.clean(df)\n",
    "\n",
    "        self.y = df.pop('income')\n",
    "        self.X = df\n",
    "        \n",
    "        # Label encode y\n",
    "        self.y_encoder = LabelEncoder()\n",
    "        self.y = self.y_encoder.fit_transform(self.y)\n",
    "        \n",
    "        # One Hot encode X\n",
    "        self.X = pd.get_dummies(self.X)\n",
    "        \n",
    "        for name in self.X.columns:\n",
    "            if self.X[name].dtype == 'object':\n",
    "                self.X[name] = self.X[name].astype('category')\n",
    "    \n",
    "    def clean(self, df):\n",
    "        return df.replace('?', np.nan).dropna().drop('fnlwgt', axis=1)\n",
    "\n",
    "\n",
    "    def train_test_split(self):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=0.2)\n",
    "        y_train = pd.Series(y_train, index=X_train.index)\n",
    "        y_test = pd.Series(y_test, index=X_test.index)\n",
    "        return (X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingModel:\n",
    "    def __init__(self, input_shape):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(64, activation='relu', input_shape=input_shape))\n",
    "        self.model.add(Dropout(0.3))\n",
    "        self.model.add(Dense(128, activation='relu'))\n",
    "        self.model.add(Dropout(0.3))\n",
    "        self.model.add(Dense(128, activation='relu'))\n",
    "        self.model.add(Dense(1, activation='sigmoid'))\n",
    "        self.model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    def fit(self, data, label):\n",
    "        self.model.fit(data, label, epochs=1, batch_size=128, verbose=0)\n",
    "\n",
    "    def predict(self, data):\n",
    "        return self.model.predict_classes(data)\n",
    "    \n",
    "    def evaluate(self, X_test, y_test, print_report=True):\n",
    "        y_predicted = self.predict(X_test)\n",
    "        y_predicted_probs = self.model.predict_proba(X_test)\n",
    "        if print_report:\n",
    "            self.print_report(y_test, y_predicted, y_predicted_probs)\n",
    "        else:\n",
    "            accuracy = accuracy_score(y_test, y_predicted)\n",
    "            report = classification_report(y_test, y_predicted, output_dict=True)\n",
    "            auc_score = roc_auc_score(y_test, y_predicted_probs)\n",
    "            matrix = confusion_matrix(y_test, y_predicted)\n",
    "\n",
    "            return {\n",
    "                'accuracy': accuracy,\n",
    "                'auc_score': auc_score,\n",
    "                **report['weighted avg'],\n",
    "            }\n",
    "\n",
    "    def print_report(self, test, predicted, predicted_probs):\n",
    "        accuracy = accuracy_score(test, predicted)\n",
    "        report = classification_report(test, predicted)\n",
    "        matrix = confusion_matrix(test, predicted)\n",
    "\n",
    "        print('Accuracy score: {:.5f}'.format(accuracy))\n",
    "        print('-' * 20)\n",
    "        print('Confusion Matrix:')\n",
    "        print(matrix)\n",
    "        print('-' * 20)\n",
    "        print(report)\n",
    "        print('-' * 20)\n",
    "        print('AUC score: {:.5f}'.format(roc_auc_score(test, predicted_probs)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perturbator:\n",
    "    def perturbate(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainRunner:\n",
    "    def __init__(self, name, perturbators=[]):\n",
    "        self.perturbators = perturbators\n",
    "        self.model = None\n",
    "        self.name = name\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "\n",
    "    def preprocess(self, X, y):\n",
    "        for perturbator in self.perturbators:\n",
    "            X = perturbator.perturbate(X)\n",
    "        X, y = X.align(y, join='inner', axis=0)\n",
    "        return (X, y)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        shape = (X.shape[1], )\n",
    "        self.model = TrainingModel(shape)\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def evaluate(self, X, y, print_report=False):\n",
    "        if self.model is not None:\n",
    "            report = self.model.evaluate(X, y, print_report=print_report)\n",
    "            return report\n",
    "        else:\n",
    "            raise Exception('Must call fit before evaluate a model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeit(func, *args, **kwargs):\n",
    "    start_time = time.time()\n",
    "    result = func(*args, **kwargs)\n",
    "    end_time = time.time()\n",
    "    return (result, end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile(runners, X_train, y_train, X_test, y_test):\n",
    "    runners_profile = {}\n",
    "    for runner in runners:\n",
    "        result, preprocess_time = timeit(runner.preprocess, X_train, y_train)\n",
    "        X_preprocessed, y_preprocessed = result\n",
    "        runner.fit(X_preprocessed, y_preprocessed)\n",
    "        report = runner.evaluate(X_test, y_test)\n",
    "        runner_profile = {\n",
    "            **report,\n",
    "            'preprocessed_time': preprocess_time\n",
    "        }\n",
    "        runners_profile[str(runner)] = runner_profile\n",
    "    return runners_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mondrian(Perturbator):\n",
    "    def __init__(self, quasi_identifiers):\n",
    "        self.quasi_identifiers = quasi_identifiers\n",
    "        \n",
    "    def is_categorical(self, df, column):\n",
    "        return str(df[column].dtype) == 'category'\n",
    "\n",
    "    def partite(self, df, partition, column):\n",
    "        \"\"\"partite the df into two partitions.\n",
    "\n",
    "            returns: A tuple of df index.\n",
    "        \"\"\"\n",
    "        df_partition = df[column][partition]\n",
    "        if self.is_categorical(df, column):\n",
    "            values = list(df_partition.unique())\n",
    "            left = df_partition.isin(values[:len(values) // 2])\n",
    "            right = df_partition.isin(values[len(values) // 2:])\n",
    "            return (df_partition[left].index, df_partition[right].index)\n",
    "        else:\n",
    "            median = df_partition.median()\n",
    "            return (df_partition[df_partition < median].index, df_partition[df_partition >= median].index)\n",
    "\n",
    "    def get_spans(self, df, partition):\n",
    "        \"\"\"get each column's span\n",
    "        \"\"\"\n",
    "        span = {}\n",
    "        for column in self.quasi_identifiers:\n",
    "            df_partition = df[column][partition]\n",
    "            if self.is_categorical(df, column):\n",
    "                span[column] = len(df_partition.unique())\n",
    "            else:\n",
    "                span[column] = df_partition.max() - df_partition.min()\n",
    "        return sorted(span.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    def validate(self, df):\n",
    "        pass\n",
    "\n",
    "    def split(self, df):\n",
    "        wip_partitions = [df.index]\n",
    "        finished_partitions = []\n",
    "\n",
    "        while len(wip_partitions) > 0:\n",
    "            partition = wip_partitions.pop(0)\n",
    "            for column, _ in self.get_spans(df, partition):\n",
    "                lp, rp = self.partite(df, partition, column)\n",
    "\n",
    "                # If either left part or right part cannot satisfied the K-anonymous condition\n",
    "                # cancel the partion and try next column.\n",
    "                if not self.validate(df.loc[lp]) or not self.validate(df.loc[rp]):\n",
    "                    continue\n",
    "\n",
    "                # If the partition is valid, continue to try next partition.\n",
    "                wip_partitions.append(lp)\n",
    "                wip_partitions.append(rp)\n",
    "                break\n",
    "            else:\n",
    "                # If the partition cannot be partited anymore, put it into finished_partitions array.\n",
    "                finished_partitions.append(partition)\n",
    "        return finished_partitions\n",
    "\n",
    "    def build_dataset(self, df, partitions):\n",
    "        dfs = []\n",
    "        for partition in partitions:\n",
    "            dfp = df.loc[partition]\n",
    "            for column in self.quasi_identifiers:\n",
    "                if dfp[column].dtype == 'int64':\n",
    "                    dfp[column] = dfp[column].mean()\n",
    "                if str(dfp[column].dtype) == 'category':\n",
    "                    dfp[column] = ','.join(list(dfp[column].unique()))\n",
    "            dfs.append(dfp)\n",
    "        return pd.concat(dfs)\n",
    "    \n",
    "    def perturbate(self, df):\n",
    "        partitions = self.split(df)\n",
    "        return self.build_dataset(df, partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class K_Anonymity(Mondrian):\n",
    "    def __init__(self, quasi_identifiers, k):\n",
    "        self.k_anonymity = k\n",
    "        super().__init__(quasi_identifiers)\n",
    "\n",
    "    def is_k_anonymous(self, partition):\n",
    "        return not (partition.shape[0] < self.k_anonymity)\n",
    "\n",
    "    def validate(self, df):\n",
    "        return self.is_k_anonymous(df)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'K Anonymity - {}'.format(self.k_anonymity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_origin, X_test_origin, y_train_origin, y_test_origin = data.train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "runners = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark before perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "original_runner = TrainRunner('Original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "runners.append(original_runner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Anonymous(KD Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "quasi_identifiers = ['age', 'educational-num', 'capital-gain', 'capital-loss', 'hours-per-week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [5, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in sizes:\n",
    "    runner = TrainRunner('K Anonymous(k={})'.format(size), [K_Anonymity(quasi_identifiers, size)])\n",
    "    runners.append(runner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KD Tree + SOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SOM_K_Anonymity(K_Anonymity):\n",
    "    def __init__(self, quasi_identifiers, k, som_size=(150, 150)):\n",
    "        self.som_columns = quasi_identifiers\n",
    "        self.som_size = som_size\n",
    "        super().__init__(['x axis', 'y axis'], k)\n",
    "\n",
    "    def perturbate(self, df):\n",
    "        df_som = df[self.som_columns]\n",
    "        som = MiniSom(self.som_size[0], self.som_size[1], df_som.shape[1])\n",
    "        som.train_random(df_som.values, 10)\n",
    "        coordinates = [som.winner(series.to_numpy()) for index, series in df_som.iterrows()]\n",
    "        df_coordinates = pd.DataFrame(coordinates, index=df.index, columns=['x axis', 'y axis'])\n",
    "        df = pd.concat([df, df_coordinates], axis=1)\n",
    "        df = super().perturbate(df)\n",
    "        df.drop(['x axis', 'y axis'], axis=1, inplace=True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in sizes:\n",
    "    runner = TrainRunner('SOM KDTree(k={})'.format(size), [SOM_K_Anonymity(quasi_identifiers, size)])\n",
    "    runners.append(runner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\phil\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "pf = profile(runners, X_train_origin, y_train_origin, X_test_origin, y_test_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original</th>\n",
       "      <th>K Anonymous(k=5)</th>\n",
       "      <th>K Anonymous(k=10)</th>\n",
       "      <th>SOM KDTree(k=5)</th>\n",
       "      <th>SOM KDTree(k=10)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.777667</td>\n",
       "      <td>0.773245</td>\n",
       "      <td>0.748038</td>\n",
       "      <td>0.772029</td>\n",
       "      <td>0.800995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc_score</th>\n",
       "      <td>0.625664</td>\n",
       "      <td>0.600217</td>\n",
       "      <td>0.364495</td>\n",
       "      <td>0.822698</td>\n",
       "      <td>0.837554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.759078</td>\n",
       "      <td>0.736292</td>\n",
       "      <td>0.640215</td>\n",
       "      <td>0.743902</td>\n",
       "      <td>0.793218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.757300</td>\n",
       "      <td>0.748139</td>\n",
       "      <td>0.559560</td>\n",
       "      <td>0.746755</td>\n",
       "      <td>0.790320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preprocessed_time</th>\n",
       "      <td>0.002001</td>\n",
       "      <td>31.787972</td>\n",
       "      <td>22.445858</td>\n",
       "      <td>24.051003</td>\n",
       "      <td>24.318004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.777667</td>\n",
       "      <td>0.773245</td>\n",
       "      <td>0.748038</td>\n",
       "      <td>0.772029</td>\n",
       "      <td>0.800995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>9045.000000</td>\n",
       "      <td>9045.000000</td>\n",
       "      <td>9045.000000</td>\n",
       "      <td>9045.000000</td>\n",
       "      <td>9045.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Original  K Anonymous(k=5)  K Anonymous(k=10)  \\\n",
       "accuracy              0.777667          0.773245           0.748038   \n",
       "auc_score             0.625664          0.600217           0.364495   \n",
       "f1-score              0.759078          0.736292           0.640215   \n",
       "precision             0.757300          0.748139           0.559560   \n",
       "preprocessed_time     0.002001         31.787972          22.445858   \n",
       "recall                0.777667          0.773245           0.748038   \n",
       "support            9045.000000       9045.000000        9045.000000   \n",
       "\n",
       "                   SOM KDTree(k=5)  SOM KDTree(k=10)  \n",
       "accuracy                  0.772029          0.800995  \n",
       "auc_score                 0.822698          0.837554  \n",
       "f1-score                  0.743902          0.793218  \n",
       "precision                 0.746755          0.790320  \n",
       "preprocessed_time        24.051003         24.318004  \n",
       "recall                    0.772029          0.800995  \n",
       "support                9045.000000       9045.000000  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
